{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feature engineering methods\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "import spacy\n",
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "from bs4 import UnicodeDammit\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "nlp = spacy.load(\"en\")\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "\n",
    "question_tokens = set([\"why\", \"how\", \"what\", \"when\", \"which\", \"who\", \"whose\", \"whom\"])\n",
    "\n",
    "\n",
    "def set_overlap_score_model(questions_df):\n",
    "    \"\"\"\n",
    "    appending column of set overlap percentage, where each set\n",
    "    is a set of tokens excluding stop-words and punctuation,\n",
    "    and in lemmatised form\n",
    "    \"\"\"\n",
    "    def set_overlap_score(row):\n",
    "        set1, set2 = \\\n",
    "            (set([w.lemma_.lower() for w in row[\"cleaned_question1_words\"]]),\n",
    "             set([w.lemma_.lower() for w in row[\"cleaned_question2_words\"]]))\n",
    "        return 0.0 if not len(set1.union(set2)) else 1.0 * len(set1.intersection(set2)) / len(set1.union(set2))\n",
    "    questions_df[\"cleaned_question1_words\"] = questions_df[\"question1\"].map(clean_statement)\n",
    "    questions_df[\"cleaned_question2_words\"] = questions_df[\"question2\"].map(clean_statement)\n",
    "\n",
    "    questions_df[\"score\"] = questions_df.apply(set_overlap_score, axis=1)\n",
    "\n",
    "    return questions_df\n",
    "\n",
    "\n",
    "def remove_punc(s):\n",
    "    return re.sub(r'[^\\w\\s]', '', UnicodeDammit(str(s)).markup)\n",
    "\n",
    "\n",
    "def clean_statement(s):\n",
    "    \"\"\"\n",
    "    Remove punctuation, stop words and standardise casing\n",
    "    words, and return remaining tokens\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove punctuation\n",
    "    s = remove_punc(s)\n",
    "    sentence = nlp(s)\n",
    "    sentence_with_stop_checks = [(sentence[i], sentence[i].is_stop) for i in range(len(sentence))]\n",
    "\n",
    "    return sorted([w for (w, stop_bool) in sentence_with_stop_checks if not stop_bool])\n",
    "\n",
    "\n",
    "def construct_doc_list(df):\n",
    "    \"\"\"\n",
    "    Take the question pairs DF and return a list of 2 docs per\n",
    "    row with the cleaned up sentence\n",
    "    \"\"\"\n",
    "    for index, row in df.iterrows():\n",
    "        q1, q2 = row[\"question1\"], row[\"question2\"]\n",
    "        q1_tokens, q2_tokens = clean_statement(q1), clean_statement(q2)\n",
    "\n",
    "        q1_doc = [w.lemma_.lower() for w in q1_tokens]\n",
    "        q2_doc = [w.lemma_.lower() for w in q2_tokens]\n",
    "\n",
    "        yield q1_doc\n",
    "        yield q2_doc\n",
    "\n",
    "\n",
    "def train_lda(n_topics, id2word_dictionary=None, documents=None, corpus=None):\n",
    "    \"\"\"\n",
    "    Training method for LDA. documents is a list of lists of words/tokens\n",
    "    documents is used to construct a dictionary and a corpus from which the\n",
    "    topics for LDA are inferred\n",
    "    \"\"\"\n",
    "    # Construct dictionary of words if it's not passed\n",
    "    if not id2word_dictionary:\n",
    "        id2word_dictionary = corpora.Dictionary(documents)\n",
    "\n",
    "    word2idx_dictionary = dict([(w, idx) for (idx, w) in id2word_dictionary.items()])\n",
    "\n",
    "    # Construct corpus for model\n",
    "    if documents and not corpus:\n",
    "        corpus = [id2word_dictionary.doc2bow(document) for document in documents]\n",
    "\n",
    "    # Cluster the documents into topics using LDA. number of topics is given\n",
    "    # by n_topics\n",
    "    lda_model = LdaModel(corpus=corpus,\n",
    "                         id2word=id2word_dictionary,\n",
    "                         num_topics=n_topics,\n",
    "                         update_every=1,\n",
    "                         chunksize=10000,\n",
    "                         passes=1)\n",
    "\n",
    "    \"\"\"\n",
    "    Default value for topn (number of top words to show by probability) is 10.\n",
    "    A high enough value should return the words covering most or all of the\n",
    "    probability mass\n",
    "    \"\"\"\n",
    "    topics = [lda_model.show_topic(idx, topn=50000)\n",
    "              for idx in range(0, n_topics)]\n",
    "\n",
    "    return lda_model, id2word_dictionary, word2idx_dictionary, topics\n",
    "\n",
    "\n",
    "# If a word appears only once, we ignore it completely (likely a typo)\n",
    "# Epsilon defines a smoothing constant, which makes the effect of extremely rare words smaller\n",
    "def get_weight(count, eps=10000, min_count=2):\n",
    "    if count < min_count:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1.0 / (count + eps)\n",
    "\n",
    "    \n",
    "def tfidf_word_match_share(row, weights):\n",
    "    q1words = {}\n",
    "    q2words = {}\n",
    "    for word in remove_punc(row['question1']).lower().split():\n",
    "        if word not in stops:\n",
    "            q1words[word] = 1\n",
    "    for word in remove_punc(row['question2']).lower().split():\n",
    "        if word not in stops:\n",
    "            q2words[word] = 1\n",
    "    if len(q1words) == 0 or len(q2words) == 0:\n",
    "        # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
    "        return 0\n",
    "    \n",
    "    shared_weights = [weights.get(w, 0) for w in q1words.keys() if w in q2words] + [weights.get(w, 0) for w in q2words.keys() if w in q1words]\n",
    "    total_weights = [weights.get(w, 0) for w in q1words] + [weights.get(w, 0) for w in q2words]\n",
    "    \n",
    "    R = np.sum(shared_weights) / np.sum(total_weights)\n",
    "    return R\n",
    "\n",
    "\n",
    "def weighted_token_overlap_score(row):\n",
    "    cleaned_question1_words = clean_statement(row[\"question1\"])\n",
    "    cleaned_question2_words = clean_statement(row[\"question2\"])\n",
    "    \n",
    "    set1, set2 = \\\n",
    "            (set([w.lemma_.lower() for w in cleaned_question1_words]),\n",
    "             set([w.lemma_.lower() for w in cleaned_question2_words]))\n",
    "        \n",
    "    return (1.0 * len(set1.intersection(set2)) / (len(set1.union(set2)) or 1)) * \\\n",
    "            (\n",
    "                min(len(str(row[\"question1\"])), len(str(row[\"question2\"]))) / \n",
    "                (1.0 * max(len(str(row[\"question1\"])), len(str(row[\"question2\"]))))\n",
    "            )\n",
    "    \n",
    "def stops_ratios(row):\n",
    "    q1_tokens = [t.lower() for t in remove_punc(row[\"question1\"]).split()]\n",
    "    q2_tokens = [t.lower() for t in remove_punc(row[\"question2\"]).split()]\n",
    "    q1_stops = set([t for t in q1_tokens if t in stops])\n",
    "    q2_stops = set([t for t in q2_tokens if t in stops])\n",
    "    return (\n",
    "        float(len(q1_stops.intersection(q2_stops))) / (len(q1_stops.union(q2_stops)) or 1.0),\n",
    "        float(len(q1_stops)) / (len(q1_tokens) or 1.0),\n",
    "        float(len(q2_stops)) / (len(q2_tokens) or 1.0),\n",
    "        math.fabs(float(len(q1_stops)) / (len(q1_tokens) or 1.0) - float(len(q2_stops)) / (len(q2_tokens) or 1.0))\n",
    "    )\n",
    "\n",
    "def question_tokens_ratio(row):\n",
    "    q1_quest_tokens = set([t.lower() for t in remove_punc(row[\"question1\"]) if t.lower() in question_tokens])\n",
    "    q2_quest_tokens = set([t.lower() for t in remove_punc(row[\"question2\"]) if t.lower() in question_tokens])\n",
    "    return (\n",
    "        float(len(q1_quest_tokens.intersection(q2_quest_tokens))) / (len(q1_quest_tokens.union(q2_quest_tokens)) or 1.0)\n",
    "    )\n",
    "\n",
    "\n",
    "# def features(row, lda_model, word2idx_dict, n_lda_topics=10):\n",
    "def features(df, lda_model, word2idx_dict, n_lda_topics=10, word_weights={}):\n",
    "    \"\"\"\n",
    "    More features to implement:\n",
    "    - TF-IDF or similar scheme string similarity (with and without stopwords)\n",
    "    - Better LDA model by incorporating children, synonyms, related concepts, subtrees\n",
    "    - Difference in lengths between both questions, ratio of lengths\n",
    "        - for full original questions\n",
    "        - noun phrases\n",
    "        - after filtering stopwords\n",
    "    - Number of sentences in both questions, ratios, difference in number\n",
    "    - Question tokens in both questions (why, how, when, what, ..), set intersection, difference, etc\n",
    "    - Stop words in both questions, stopq1/len(q1), stopq2/len(q2), stopq1.intersect(stopq2),...\n",
    "    \"\"\"\n",
    "\n",
    "    features_col = pandas.Series([[]], index=np.arange(df.shape[0]))\n",
    "\n",
    "    for (idx, row) in list(df.iterrows()):\n",
    "        q1, q2 = row[\"question1\"], row[\"question2\"]\n",
    "        q1_tokens, q2_tokens = clean_statement(q1), clean_statement(q2)\n",
    "        tf_idf_sim = tfidf_word_match_share(row, word_weights)\n",
    "\n",
    "        # LDA related features\n",
    "        q1_lda_doc = [w.lemma_.lower() for w in q1_tokens]\n",
    "        q2_lda_doc = [w.lemma_.lower() for w in q2_tokens]\n",
    "        q1_topic_probs = dict(\n",
    "            lda_model.get_document_topics(Counter([word2idx_dict[w] for w in q1_lda_doc if w in word2idx_dict]).items())\n",
    "        )\n",
    "        q2_topic_probs = dict(\n",
    "            lda_model.get_document_topics(Counter([word2idx_dict[w] for w in q2_lda_doc if w in word2idx_dict]).items())\n",
    "        )\n",
    "\n",
    "        q1_topic_probs = [(t, q1_topic_probs[t]) if t in q1_topic_probs else (t, 0.0) for t in range(n_lda_topics)]\n",
    "        q2_topic_probs = [(t, q2_topic_probs[t]) if t in q2_topic_probs else (t, 0.0) for t in range(n_lda_topics)]\n",
    "\n",
    "        q1_topic_vector = np.array([prob for (topic, prob) in q1_topic_probs])\n",
    "        q2_topic_vector = np.array([prob for (topic, prob) in q2_topic_probs])\n",
    "        diff_topic_vector = q1_topic_vector - q2_topic_vector\n",
    "\n",
    "        q1_doc = nlp(UnicodeDammit(' '.join([w.lemma_.lower() for w in q1_tokens])).markup) if q1_tokens else None\n",
    "        q2_doc = nlp(UnicodeDammit(' '.join([w.lemma_.lower() for w in q2_tokens])).markup) if q2_tokens else None\n",
    "\n",
    "        q1_vector, q2_vector = (\n",
    "            q1_doc.vector if q1_doc and q1_doc.has_vector else None,\n",
    "            q2_doc.vector if q2_doc and q2_doc.has_vector else None\n",
    "        )\n",
    "\n",
    "        q1_tokens_set = set(q1_tokens)\n",
    "        q2_tokens_set = set(q2_tokens)\n",
    "\n",
    "        token_overlap_ratio = (\n",
    "            0.0 if not len(q1_tokens_set.union(q2_tokens_set))\n",
    "            else 1.0 * float(len(q1_tokens_set.intersection(q2_tokens_set))) / len(q1_tokens_set.union(q2_tokens_set))\n",
    "        )\n",
    "        \n",
    "        # Weighted TF-IDF sim\n",
    "        wt_token_overlap_score = weighted_token_overlap_score(row)\n",
    "        \n",
    "        # Stop word occurrence\n",
    "        (stops_ratio, stops_ratio_q1, stops_ratio_q2, stops_diff) = stops_ratios(row)\n",
    "\n",
    "        if q1_vector is not None and q2_vector is not None:\n",
    "            dot_product = q1_vector.dot(q2_vector) \n",
    "            cosine_sim = cosine_similarity(q1_vector, q2_vector)[0][0]\n",
    "            euclidean_dist = np.linalg.norm(q1_vector - q2_vector)\n",
    "            euclidean_lda_probs_dist = np.linalg.norm(diff_topic_vector)\n",
    "        else:\n",
    "            dot_product = cosine_sim = 0.0\n",
    "            euclidean_dist = euclidean_lda_probs_dist = 100.0 # Not a very good hack\n",
    "\n",
    "        feature_list = [\n",
    "            token_overlap_ratio,\n",
    "            float(token_overlap_ratio == 0),\n",
    "            float(token_overlap_ratio == 1),\n",
    "            dot_product,\n",
    "            cosine_sim,\n",
    "#             euclidean_dist,\n",
    "#             euclidean_lda_probs_dist,\n",
    "            tf_idf_sim,\n",
    "            wt_token_overlap_score,\n",
    "            stops_ratio,\n",
    "            stops_ratio_q1,\n",
    "            stops_ratio_q2,\n",
    "            stops_diff\n",
    "        ]\n",
    "        feature_list.extend(list(diff_topic_vector))\n",
    "\n",
    "        # return feature_list\n",
    "        features_col[idx] = feature_list\n",
    "\n",
    "    df[\"features\"] = features_col\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Forest model\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "from sklearn.cross_validation import train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "\n",
    "def predict_rf(row, model):\n",
    "    \"\"\"\n",
    "    Assumes row object has a `features` column\n",
    "    with the same features as those on which\n",
    "    `model` was trained\n",
    "    \"\"\"\n",
    "    return float(model.predict_proba(np.array(row[\"features\"]))[0][1])\n",
    "\n",
    "class RandomForestModel():\n",
    "    n_trees = 400\n",
    "    # test_size = 0.3\n",
    "    rf_max_features = None\n",
    "    folds = 10\n",
    "\n",
    "    def train(self, training_df, cv=True):\n",
    "        \"\"\"\n",
    "        Expects a `features` column which holds a\n",
    "        list of floats to be used as features for\n",
    "        the classifier and an integer `label` column\n",
    "        encoding the output to be predicted\n",
    "        \"\"\"\n",
    "        featureMatrix, labelVector = training_df[\"features\"], training_df[\"label\"]\n",
    "        featureMatrix = np.array([list(f) for f in featureMatrix])\n",
    "        featureMatrix = np.nan_to_num(featureMatrix)\n",
    "        labelVector = np.array(list(labelVector))\n",
    "        labelVector = np.nan_to_num(labelVector)\n",
    "\n",
    "        auc_list = []\n",
    "        logloss_list = []\n",
    "\n",
    "        if cv:\n",
    "            idx = 1\n",
    "            for train, test in StratifiedKFold(labelVector, self.folds):\n",
    "                print \"Starting Cross Validation Fold {}\".format(idx)\n",
    "\n",
    "                x_train, y_train = featureMatrix[train], labelVector[train]\n",
    "                x_test, y_test = featureMatrix[test], labelVector[test]\n",
    "                x_train = np.asarray(x_train)\n",
    "                y_train = np.asarray(y_train)\n",
    "                x_test = np.asarray(x_test)\n",
    "                y_test = np.asarray(y_test)\n",
    "\n",
    "                model = RandomForestClassifier(n_estimators=self.n_trees, max_features=self.rf_max_features, class_weight=\"auto\")\\\n",
    "                    if self.rf_max_features else RandomForestClassifier(n_estimators=self.n_trees, class_weight=\"auto\")\n",
    "\n",
    "                model.fit(x_train, y_train)\n",
    "\n",
    "                predictions = model.predict_proba(x_test)[:, 1]\n",
    "                fprArray, tprArray, thres = roc_curve(y_test, predictions)\n",
    "                roc_auc = auc(fprArray, tprArray)\n",
    "                logloss = binary_logloss(y_test, predictions)\n",
    "                auc_list.append(roc_auc)\n",
    "                logloss_list.append(logloss_list)\n",
    "\n",
    "                print \"CV Fold result: AUC is {auc} and Log Loss is {loss}\".format(auc=roc_auc, loss=logloss)\n",
    "                print \"#########\"\n",
    "\n",
    "                idx += 1\n",
    "            \n",
    "            # Just for fast testing\n",
    "            return\n",
    "\n",
    "            model = RandomForestClassifier(n_estimators=self.n_trees, max_features=self.rf_max_features, class_weight=\"auto\")\\\n",
    "                if self.rf_max_features else RandomForestClassifier(n_estimators=self.n_trees, class_weight=\"auto\")\n",
    "\n",
    "            roc_auc = np.mean(auc_list)\n",
    "            logloss = np.mean(logloss_list)\n",
    "            print \"<======================================>\"\n",
    "            print \"Finished cross validation experiments!\"\n",
    "            print \"Average AUC is {auc} and average Log Loss is {loss}\".format(auc=roc_auc, loss=logloss)\n",
    "            print \"Starting full model training!\"\n",
    "\n",
    "            model.fit(featureMatrix, labelVector)\n",
    "\n",
    "            return {'model': model, 'roc_auc': roc_auc, 'logloss': logloss}\n",
    "        else:\n",
    "            model = RandomForestClassifier(n_estimators=self.n_trees, max_features=self.rf_max_features, class_weight=\"auto\")\\\n",
    "                if self.rf_max_features else RandomForestClassifier(n_estimators=self.n_trees, class_weight=\"auto\")\n",
    "\n",
    "            model.fit(featureMatrix, labelVector)\n",
    "\n",
    "            return {'model': model}\n",
    "\n",
    "    def compute_precision_scores(self, y_pred, y_true, prob_thresholds):\n",
    "        \"\"\"\n",
    "        Compute precision scores at different probability thresholds\n",
    "        This allows us to pick a probability threshold for the classifier\n",
    "        given a desired precision score\n",
    "            pr = tpr  /  (tpr + fpr)\n",
    "        returns: list((precision_score, prob_thres))\n",
    "        \"\"\"\n",
    "        precisions = []\n",
    "        for prob_thres in prob_thresholds:\n",
    "            flagged_idxes = filter(lambda idx: y_pred[idx] >= prob_thres, range(len(y_pred)))\n",
    "            true_flagged_idxes = filter(lambda idx: y_pred[idx] >= prob_thres and y_true[idx] == 1, range(len(y_pred)))\n",
    "            precision = (len(true_flagged_idxes) / float(len(flagged_idxes))) if len(flagged_idxes) else 0.0\n",
    "            precisions.append((precision, prob_thres))\n",
    "\n",
    "        return sorted(precisions, key=lambda (prec, prob): prec)\n",
    "\n",
    "    def compute_accuracy_scores(self, y_pred, y_true, prob_thresholds):\n",
    "        \"\"\"\n",
    "        Compute accuracy scores at different probability thresholds\n",
    "        This allows us to pick a probability threshold for the classifier\n",
    "        given a desired precision score\n",
    "        returns: list((accuracy_score, prob_thres))\n",
    "        \"\"\"\n",
    "        accuracy_scores = []\n",
    "        for prob_thres in prob_thresholds:\n",
    "            correct_predicted_data_points = filter(lambda prob_idx:\n",
    "                                                   (y_pred[prob_idx] >= prob_thres and y_true[prob_idx] == 1) or\n",
    "                                                   (y_pred[prob_idx] < prob_thres and y_true[prob_idx] == 0),\n",
    "                                                   range(len(y_pred)))\n",
    "            accuracy = len(correct_predicted_data_points) / float(len(y_true)) if len(y_true) else 0.0\n",
    "            accuracy_scores.append((accuracy, prob_thres))\n",
    "\n",
    "        return sorted(accuracy_scores, key=lambda (acc, prob): acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# XgBoost model\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "from sklearn.cross_validation import train_test_split, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "def binary_logloss(act, pred):\n",
    "    \"\"\"\n",
    "    act and pred are vectors of actual class\n",
    "    and prediction probability of class 1,\n",
    "    respectively\n",
    "    \"\"\"\n",
    "    epsilon = 1e-15\n",
    "    pred = sp.maximum(epsilon, pred)\n",
    "    pred = sp.minimum(1 - epsilon, pred)\n",
    "    ll = sum(act * sp.log(pred) + sp.subtract(1, act) * sp.log(sp.subtract(1, pred)))\n",
    "    ll = ll * -1.0 / len(act)\n",
    "    return ll\n",
    "\n",
    "\n",
    "def xgboost_eval(act, pred):\n",
    "    return 'error', binary_logloss(act, pred)\n",
    "\n",
    "\n",
    "def predict_xgboost(row, model):\n",
    "    \"\"\"\n",
    "    Assumes row object has a `features` column\n",
    "    with the same features as those on which\n",
    "    `model` was trained\n",
    "    \"\"\"\n",
    "    return float(model.predict(np.array(row[\"features\"]))[0])\n",
    "\n",
    "\n",
    "class XgBoostModel():\n",
    "    n_boost_rounds = 2000\n",
    "    max_depth = 5\n",
    "    objective = 'binary:logistic'\n",
    "    eval_metric = \"logloss\"\n",
    "    early_stopping_rounds = 70\n",
    "    folds = 10\n",
    "    learning_rate = 0.1\n",
    "    scale_pos_weight = 1\n",
    "    gamma = 0.1\n",
    "\n",
    "    def train(self, training_df, cv=True):\n",
    "        \"\"\"\n",
    "        Expects a `features` column which holds a\n",
    "        list of floats to be used as features for\n",
    "        the classifier and an integer `label` column\n",
    "        encoding the output to be predicted\n",
    "        \"\"\"\n",
    "        featureMatrix, labelVector = training_df[\"features\"], training_df[\"label\"]\n",
    "        featureMatrix = np.array([list(f) for f in featureMatrix])\n",
    "        featureMatrix = np.nan_to_num(featureMatrix)\n",
    "        labelVector = np.array(list(labelVector))\n",
    "        labelVector = np.nan_to_num(labelVector)\n",
    "\n",
    "        auc_list = []\n",
    "        logloss_list = []\n",
    "\n",
    "        if cv:\n",
    "            idx = 1\n",
    "            for train, test in StratifiedKFold(labelVector, self.folds):\n",
    "                print \"Starting Cross Validation Fold {}\".format(idx)\n",
    "\n",
    "                x_train, y_train = featureMatrix[train], labelVector[train]\n",
    "                x_test, y_test = featureMatrix[test], labelVector[test]\n",
    "                x_train = np.asarray(x_train)\n",
    "                y_train = np.asarray(y_train)\n",
    "                x_test = np.asarray(x_test)\n",
    "                y_test = np.asarray(y_test)\n",
    "                \n",
    "                params = {}\n",
    "                params['objective'] = self.objective\n",
    "                params['eval_metric'] = self.eval_metric\n",
    "                params['eta'] = self.learning_rate\n",
    "                params['max_depth'] = self.max_depth\n",
    "                params['scale_pos_weight'] = self.scale_pos_weight\n",
    "                params['gamma'] = self.gamma\n",
    "                params['silent'] = 1\n",
    "\n",
    "                d_train = xgb.DMatrix(x_train, label=y_train)\n",
    "                d_valid = xgb.DMatrix(x_test, label=y_test)\n",
    "                \n",
    "                watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "                \n",
    "                model = xgb.train(\n",
    "                    params,\n",
    "                    d_train,\n",
    "                    self.n_boost_rounds,\n",
    "                    watchlist,\n",
    "                    early_stopping_rounds=self.early_stopping_rounds\n",
    "                )\n",
    "\n",
    "                x_test_df = pandas.DataFrame(x_test, columns=[\"feature_%s\" % str(i) for i in range(x_test.shape[1])])\n",
    "                predictions = model.predict(xgb.DMatrix(x_test_df))\n",
    "                                \n",
    "                fprArray, tprArray, thres = roc_curve(y_test, predictions)\n",
    "                roc_auc = auc(fprArray, tprArray)\n",
    "                logloss = binary_logloss(y_test, predictions)\n",
    "                auc_list.append(roc_auc)\n",
    "                logloss_list.append(logloss_list)\n",
    "\n",
    "                print \"CV Fold result: AUC is {auc} and Log Loss is {loss}\".format(auc=roc_auc, loss=logloss)\n",
    "                print \"#########\"\n",
    "\n",
    "                idx += 1\n",
    "            \n",
    "            # Just for fast testing\n",
    "            return\n",
    "\n",
    "            roc_auc = np.mean(auc_list)\n",
    "            logloss = np.mean(logloss_list)\n",
    "            print \"<======================================>\"\n",
    "            print \"Finished cross validation experiments!\"\n",
    "            print \"Average AUC is {auc} and average Log Loss is {loss}\".format(auc=roc_auc, loss=logloss)\n",
    "            print \"Starting full model training!\"\n",
    "\n",
    "#             model = xgb.XGBClassifier(max_depth=self.max_depth, n_estimators=self.n_trees)\n",
    "#             model.fit(featureMatrix, labelVector, eval_metric=self.eval_metric)#, early_stopping_rounds=self.early_stopping_rounds)\n",
    "            # make prediction\n",
    "            # preds = model.predict(x_test)\n",
    "\n",
    "            return {'model': model, 'roc_auc': roc_auc, 'logloss': logloss}\n",
    "        else:\n",
    "            model = xgb.XGBClassifier(max_depth=self.max_depth, n_estimators=self.n_trees)\n",
    "            model.fit(featureMatrix, labelVector, eval_metric=self.eval_metric)#, early_stopping_rounds=self.early_stopping_rounds)\n",
    "\n",
    "            return {'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "\n",
    "train_path = \"/Users/mohamedabdelbary/Documents/kaggle_quora/train.csv\"\n",
    "models_path = \"/Users/mohamedabdelbary/Documents/kaggle_quora/models.pkl\"\n",
    "train_pred_path = \"/Users/mohamedabdelbary/Documents/kaggle_quora/train_preds.csv\"\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas\n",
    "from functools import partial\n",
    "from collections import Counter\n",
    "\n",
    "def read_data(path):\n",
    "    return pandas.read_csv(path)\n",
    "\n",
    "n_sample = 100000\n",
    "full_df = read_data(train_path)\n",
    "rows = np.random.choice(full_df.index.values, n_sample)\n",
    "df = full_df.ix[rows]\n",
    "\n",
    "questions = pandas.Series(df['question1'].tolist() + df['question2'].tolist()).astype(str)\n",
    "questions = [remove_punc(q).lower() for q in questions]\n",
    "eps = 500 \n",
    "words = (\" \".join(questions)).lower().split()\n",
    "counts = Counter(words)\n",
    "weights = {word: get_weight(count, eps=eps) for word, count in counts.items()}\n",
    "\n",
    "# df = read_data(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LDA modelling!\n"
     ]
    }
   ],
   "source": [
    "# Train topic model\n",
    "n_lda_topics = 20\n",
    "print \"Starting LDA modelling!\"\n",
    "\n",
    "doc_list_lda_train = list(construct_doc_list(df))\n",
    "lda_model, id2word_dictionary, word2idx_dictionary, topics = \\\n",
    "    train_lda(n_lda_topics,\n",
    "              documents=doc_list_lda_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting feature construction!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohamedabdelbary/.pyenv/versions/2.7.8/lib/python2.7/site-packages/ipykernel/__main__.py:253: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/mohamedabdelbary/.pyenv/versions/2.7.8/lib/python2.7/site-packages/ipykernel/__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Feature construction\n",
    "print \"Starting feature construction!\"\n",
    "feature_method = partial(\n",
    "    features,\n",
    "    lda_model=lda_model,\n",
    "    word2idx_dict=word2idx_dictionary,\n",
    "    n_lda_topics=n_lda_topics,\n",
    "    word_weights=weights\n",
    "    )\n",
    "df = feature_method(df)\n",
    "df[\"label\"] = df[\"is_duplicate\"].map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.191234956605\n"
     ]
    }
   ],
   "source": [
    "#Â Purely for experimenting!! This oversampling process can lead to overfitting\n",
    "# and is generally not very good ML practise\n",
    "pos_train = df[df[\"is_duplicate\"] == 1]\n",
    "neg_train = df[df[\"is_duplicate\"] == 0]\n",
    "\n",
    "# Now we oversample the negative class\n",
    "# There is likely a much more elegant way to do this...\n",
    "p = 0.165\n",
    "scale = ((float(len(pos_train)) / (len(pos_train) + len(neg_train))) / p) - 1\n",
    "while scale > 1:\n",
    "    neg_train = pandas.concat([neg_train, neg_train])\n",
    "    scale -=1\n",
    "neg_train = pandas.concat([neg_train, neg_train[:int(scale * len(neg_train))]])\n",
    "print len(pos_train) / float(len(pos_train) + len(neg_train))\n",
    "\n",
    "df_resampled = pandas.concat([pos_train, neg_train])\n",
    "y_train = (np.zeros(len(pos_train)) + 1).tolist() + np.zeros(len(neg_train)).tolist()\n",
    "del pos_train, neg_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Cross Validation Fold 1\n",
      "CV Fold result: AUC is 0.889879154053 and Log Loss is 0.405203875959\n",
      "#########\n",
      "Starting Cross Validation Fold 2\n",
      "CV Fold result: AUC is 0.893805579495 and Log Loss is 0.400139766151\n",
      "#########\n",
      "Starting Cross Validation Fold 3\n",
      "CV Fold result: AUC is 0.894732860574 and Log Loss is 0.404043903714\n",
      "#########\n",
      "Starting Cross Validation Fold 4\n",
      "CV Fold result: AUC is 0.887795383009 and Log Loss is 0.406265820267\n",
      "#########\n",
      "Starting Cross Validation Fold 5\n",
      "CV Fold result: AUC is 0.887664757364 and Log Loss is 0.406328622121\n",
      "#########\n",
      "Starting Cross Validation Fold 6\n",
      "CV Fold result: AUC is 0.884218301149 and Log Loss is 0.411929958619\n",
      "#########\n",
      "Starting Cross Validation Fold 7\n",
      "CV Fold result: AUC is 0.889516163899 and Log Loss is 0.403089507674\n",
      "#########\n",
      "Starting Cross Validation Fold 8\n",
      "CV Fold result: AUC is 0.888630227929 and Log Loss is 0.406444776011\n",
      "#########\n",
      "Starting Cross Validation Fold 9\n",
      "CV Fold result: AUC is 0.888765576276 and Log Loss is 0.407199716697\n",
      "#########\n",
      "Starting Cross Validation Fold 10\n",
      "CV Fold result: AUC is 0.88494979954 and Log Loss is 0.411820455007\n",
      "#########\n"
     ]
    }
   ],
   "source": [
    "# Model training\n",
    "# model = XgBoostModel()\n",
    "model = RandomForestModel()\n",
    "model_obj = model.train(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
